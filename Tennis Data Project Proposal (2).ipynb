{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7500f890-b257-4407-b77f-46b980f47afc",
   "metadata": {},
   "source": [
    "# Relationship between a player's rank and height #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae463889-dc82-4653-981c-a93ab78227f7",
   "metadata": {},
   "source": [
    "## Introduction ##\n",
    "With approximately 87 million playing tennis around the world, Tennis is one of the most popular sports in the world.  With a total of 3873 professional players (ITF Global Tennis Report 2019), it is no surprise that it is one of the most-watched sports on TV. \n",
    "\n",
    "“The Association of Tennis Professionals (ATP) is the governing body of the men’s professional tennis circuits– the ATP Tour, the ATP Challenger Tour, and the ATP Champions Tour.”(Wikipedia) ATP rankings are a tool used to quantify the qualifications of the players. \n",
    "\n",
    "The dataset we have attained includes information relevant to the ATP tournaments’ statistics. \n",
    "It has information about the tournament locations, the surface, draw size, tournament level, date, match number, etc. \n",
    "\n",
    "We would like to address whether there is a clear relationship between a winner’s rank points and their height. This can be accomplished by having a classification approach and trying to predict the height of a winner by looking at their rank point. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad0bba-98a1-4092-bbf5-6b66fb65de46",
   "metadata": {},
   "source": [
    "## Methods and Results ## \n",
    "We will first load our original data from the source (ATP), by downloading it and naming the file “Tennis_Data.csv” for easy identification. Then we will upload it to our Jupyter folder before creating a new Notebook on Jupyter to start wrangling and cleaning the data. By importing pandas as pd, we can read the CSV file into our notebook by using the “read_csv”  command.\n",
    "\n",
    "We labeled this dataset, _\"tennis_data\"_  which gives us a complicated and messy table of information regarding our data. Looking over this table, we can see that there are rows with blank areas or information not needed for our analysis. We removed these rows by using the command “skiprows” and selecting rows ... and ... to remove. While this greatly cleans up the table, it is still quite unkempt. The columns face the same problem as we had with the rows, as, some of the columns contain information, or lack thereof, that we do not require. We solve this by using three commands: “loc”, “columns”, and “isin”. By naming the columns to remove in hand with these three commands, we successfully remove any unnecessary columns from the “Tennis_data” and update it to “Tennis_data_2”. Our last step is making sure our table is labeled correctly. There was one unnamed column, which is incorrect. To change this, we use the “rename” and “inplace” command. By setting the “inplace” to equal to “True”, we can change the column name to its correct term: “Serial number”. This finishes our tidy of data from our original downloaded format to a new, clearer, concise and clearer format for our analysis. This includes: ...,...,..... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46df82-2899-4419-8277-5d76518112ba",
   "metadata": {},
   "source": [
    "## Methods and Results ##\n",
    "First we will start by loading the data as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ded6ed-10b2-4cd4-b518-2f5fe3acabef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>...</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>300</td>\n",
       "      <td>105453</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>299</td>\n",
       "      <td>106421</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>298</td>\n",
       "      <td>105453</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>297</td>\n",
       "      <td>104542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>296</td>\n",
       "      <td>106421</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1855.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 tourney_id tourney_name surface  draw_size tourney_level  \\\n",
       "0           0  2019-M020     Brisbane    Hard         32             A   \n",
       "1           1  2019-M020     Brisbane    Hard         32             A   \n",
       "2           2  2019-M020     Brisbane    Hard         32             A   \n",
       "3           3  2019-M020     Brisbane    Hard         32             A   \n",
       "4           4  2019-M020     Brisbane    Hard         32             A   \n",
       "\n",
       "   tourney_date  match_num  winner_id winner_seed  ... l_1stIn l_1stWon  \\\n",
       "0      20181231        300     105453           2  ...    54.0     34.0   \n",
       "1      20181231        299     106421           4  ...    52.0     36.0   \n",
       "2      20181231        298     105453           2  ...    27.0     15.0   \n",
       "3      20181231        297     104542         NaN  ...    60.0     38.0   \n",
       "4      20181231        296     106421           4  ...    56.0     46.0   \n",
       "\n",
       "  l_2ndWon  l_SvGms l_bpSaved  l_bpFaced  winner_rank winner_rank_points  \\\n",
       "0     20.0     14.0      10.0       15.0          9.0             3590.0   \n",
       "1      7.0     10.0      10.0       13.0         16.0             1977.0   \n",
       "2      6.0      8.0       1.0        5.0          9.0             3590.0   \n",
       "3      9.0     11.0       4.0        6.0        239.0              200.0   \n",
       "4     19.0     15.0       2.0        4.0         16.0             1977.0   \n",
       "\n",
       "  loser_rank loser_rank_points  \n",
       "0       16.0            1977.0  \n",
       "1      239.0             200.0  \n",
       "2       40.0            1050.0  \n",
       "3       31.0            1298.0  \n",
       "4       18.0            1855.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tennis_data = pd.read_csv(\"Tennis_Dataset 1.csv\")\n",
    "tennis_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e22f3-2654-458e-96e5-913d59a92350",
   "metadata": {},
   "source": [
    "To look at the data in a nutshell, let's make use of the \"info\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0095726d-e1c1-4b7f-98c4-420387d58295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62 entries, 0 to 4921\n",
      "Data columns (total 50 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          62 non-null     int64  \n",
      " 1   tourney_id          62 non-null     object \n",
      " 2   tourney_name        62 non-null     object \n",
      " 3   surface             62 non-null     object \n",
      " 4   draw_size           62 non-null     int64  \n",
      " 5   tourney_level       62 non-null     object \n",
      " 6   tourney_date        62 non-null     int64  \n",
      " 7   match_num           62 non-null     int64  \n",
      " 8   winner_id           62 non-null     int64  \n",
      " 9   winner_seed         30 non-null     object \n",
      " 10  winner_entry        14 non-null     object \n",
      " 11  winner_name         62 non-null     object \n",
      " 12  winner_hand         62 non-null     object \n",
      " 13  winner_ht           43 non-null     float64\n",
      " 14  winner_ioc          62 non-null     object \n",
      " 15  winner_age          62 non-null     float64\n",
      " 16  loser_id            62 non-null     int64  \n",
      " 17  loser_seed          15 non-null     object \n",
      " 18  loser_entry         21 non-null     object \n",
      " 19  loser_name          62 non-null     object \n",
      " 20  loser_hand          62 non-null     object \n",
      " 21  loser_ht            35 non-null     float64\n",
      " 22  loser_ioc           62 non-null     object \n",
      " 23  loser_age           62 non-null     float64\n",
      " 24  score               62 non-null     object \n",
      " 25  best_of             62 non-null     int64  \n",
      " 26  round               62 non-null     object \n",
      " 27  minutes             62 non-null     float64\n",
      " 28  w_ace               62 non-null     float64\n",
      " 29  w_df                62 non-null     float64\n",
      " 30  w_svpt              62 non-null     float64\n",
      " 31  w_1stIn             62 non-null     float64\n",
      " 32  w_1stWon            62 non-null     float64\n",
      " 33  w_2ndWon            62 non-null     float64\n",
      " 34  w_SvGms             62 non-null     float64\n",
      " 35  w_bpSaved           62 non-null     float64\n",
      " 36  w_bpFaced           62 non-null     float64\n",
      " 37  l_ace               62 non-null     float64\n",
      " 38  l_df                62 non-null     float64\n",
      " 39  l_svpt              62 non-null     float64\n",
      " 40  l_1stIn             62 non-null     float64\n",
      " 41  l_1stWon            62 non-null     float64\n",
      " 42  l_2ndWon            62 non-null     float64\n",
      " 43  l_SvGms             62 non-null     float64\n",
      " 44  l_bpSaved           62 non-null     float64\n",
      " 45  l_bpFaced           62 non-null     float64\n",
      " 46  winner_rank         62 non-null     float64\n",
      " 47  winner_rank_points  62 non-null     float64\n",
      " 48  loser_rank          62 non-null     float64\n",
      " 49  loser_rank_points   62 non-null     float64\n",
      "dtypes: float64(27), int64(7), object(16)\n",
      "memory usage: 24.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tennis_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd590cc-a650-4c65-a3ae-716823330188",
   "metadata": {},
   "source": [
    "Now, as we want to look at only the data concerning \"Brisbane\", the Winners' Rank points and the heights, let's filter the dataset accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065607d9-81f6-42dc-94d6-f37e13a648ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>...</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>300</td>\n",
       "      <td>105453</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>299</td>\n",
       "      <td>106421</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>298</td>\n",
       "      <td>105453</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>297</td>\n",
       "      <td>104542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-M020</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20181231</td>\n",
       "      <td>296</td>\n",
       "      <td>106421</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1855.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 tourney_id tourney_name surface  draw_size tourney_level  \\\n",
       "0           0  2019-M020     Brisbane    Hard         32             A   \n",
       "1           1  2019-M020     Brisbane    Hard         32             A   \n",
       "2           2  2019-M020     Brisbane    Hard         32             A   \n",
       "3           3  2019-M020     Brisbane    Hard         32             A   \n",
       "4           4  2019-M020     Brisbane    Hard         32             A   \n",
       "\n",
       "   tourney_date  match_num  winner_id winner_seed  ... l_1stIn l_1stWon  \\\n",
       "0      20181231        300     105453           2  ...    54.0     34.0   \n",
       "1      20181231        299     106421           4  ...    52.0     36.0   \n",
       "2      20181231        298     105453           2  ...    27.0     15.0   \n",
       "3      20181231        297     104542         NaN  ...    60.0     38.0   \n",
       "4      20181231        296     106421           4  ...    56.0     46.0   \n",
       "\n",
       "  l_2ndWon  l_SvGms l_bpSaved  l_bpFaced  winner_rank winner_rank_points  \\\n",
       "0     20.0     14.0      10.0       15.0          9.0             3590.0   \n",
       "1      7.0     10.0      10.0       13.0         16.0             1977.0   \n",
       "2      6.0      8.0       1.0        5.0          9.0             3590.0   \n",
       "3      9.0     11.0       4.0        6.0        239.0              200.0   \n",
       "4     19.0     15.0       2.0        4.0         16.0             1977.0   \n",
       "\n",
       "  loser_rank loser_rank_points  \n",
       "0       16.0            1977.0  \n",
       "1      239.0             200.0  \n",
       "2       40.0            1050.0  \n",
       "3       31.0            1298.0  \n",
       "4       18.0            1855.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_data = tennis_data[tennis_data[\"tourney_name\"] == \"Brisbane\"]\n",
    "tennis_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91ad2fbd-ecec-4bc2-bdb5-af46b3c02ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>winner_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>200.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_name  winner_rank_points  winner_ht\n",
       "0     Brisbane              3590.0      178.0\n",
       "1     Brisbane              1977.0        NaN\n",
       "2     Brisbane              3590.0      178.0\n",
       "3     Brisbane               200.0      188.0\n",
       "4     Brisbane              1977.0        NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_data_2 = tennis_data.loc[:, [\"tourney_name\",\"winner_rank_points\", \"winner_ht\"]]\n",
    "tennis_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b3cba-c7c4-4fee-89a9-3d85c788944e",
   "metadata": {},
   "source": [
    "Following this, we will remove any rows with \"None\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e3287b8-f098-4517-a390-0598962f1821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>winner_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>200.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_name  winner_rank_points  winner_ht\n",
       "0     Brisbane              3590.0      178.0\n",
       "2     Brisbane              3590.0      178.0\n",
       "3     Brisbane               200.0      188.0\n",
       "5     Brisbane              1050.0      188.0\n",
       "6     Brisbane              3590.0      178.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_data_3=tennis_data_2.dropna(axis=0)\n",
    "tennis_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77747e70-06f4-40c6-b330-27b0b43f0ebf",
   "metadata": {},
   "source": [
    "Now, let's rename the headings to make it shorter and easier to use repetitively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7b5720-b803-4a96-a122-da7b2c7f47f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4607/4003346232.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tennis_data_3.rename(columns = {'tourney_name': 'Location', 'winner_rank_points':'WRP', 'winner_ht':'WH'}, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>WRP</th>\n",
       "      <th>WH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>200.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location     WRP     WH\n",
       "0  Brisbane  3590.0  178.0\n",
       "2  Brisbane  3590.0  178.0\n",
       "3  Brisbane   200.0  188.0\n",
       "5  Brisbane  1050.0  188.0\n",
       "6  Brisbane  3590.0  178.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_data_3.rename(columns = {'tourney_name': 'Location', 'winner_rank_points':'WRP', 'winner_ht':'WH'}, inplace = True)\n",
    "tennis_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c7f65-673a-4392-924b-94cef7b5d28a",
   "metadata": {},
   "source": [
    "Finally, lets visualize the data in the form of a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b03c92-0404-4a07-ab5f-f7be60583759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, dtype in df.dtypes.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-194b4ec4542e44e18e52a72663f37dd3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-194b4ec4542e44e18e52a72663f37dd3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-194b4ec4542e44e18e52a72663f37dd3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-94cf876544f015a51241d2161bb2ce89\"}, \"mark\": \"point\", \"encoding\": {\"x\": {\"field\": \"WRP\", \"scale\": {\"zero\": false}, \"title\": \"Winner Rank Points\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"WH\", \"scale\": {\"zero\": false}, \"title\": \"Winner Heights\", \"type\": \"quantitative\"}}, \"title\": \"Winners' rank points and their corressponding Heights\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-94cf876544f015a51241d2161bb2ce89\": [{\"Location\": \"Brisbane\", \"WRP\": 3590.0, \"WH\": 178.0}, {\"Location\": \"Brisbane\", \"WRP\": 3590.0, \"WH\": 178.0}, {\"Location\": \"Brisbane\", \"WRP\": 200.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1050.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 3590.0, \"WH\": 178.0}, {\"Location\": \"Brisbane\", \"WRP\": 200.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1855.0, \"WH\": 196.0}, {\"Location\": \"Brisbane\", \"WRP\": 1050.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1835.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 3590.0, \"WH\": 178.0}, {\"Location\": \"Brisbane\", \"WRP\": 200.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 200.0, \"WH\": 190.0}, {\"Location\": \"Brisbane\", \"WRP\": 1855.0, \"WH\": 196.0}, {\"Location\": \"Brisbane\", \"WRP\": 1125.0, \"WH\": 193.0}, {\"Location\": \"Brisbane\", \"WRP\": 1050.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1835.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1083.0, \"WH\": 183.0}, {\"Location\": \"Brisbane\", \"WRP\": 810.0, \"WH\": 180.0}, {\"Location\": \"Brisbane\", \"WRP\": 1010.0, \"WH\": 183.0}, {\"Location\": \"Brisbane\", \"WRP\": 809.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1302.0, \"WH\": 190.0}, {\"Location\": \"Brisbane\", \"WRP\": 436.0, \"WH\": 183.0}, {\"Location\": \"Brisbane\", \"WRP\": 1010.0, \"WH\": 183.0}, {\"Location\": \"Brisbane\", \"WRP\": 2010.0, \"WH\": 193.0}, {\"Location\": \"Brisbane\", \"WRP\": 5150.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1010.0, \"WH\": 183.0}, {\"Location\": \"Brisbane\", \"WRP\": 5150.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 1010.0, \"WH\": 183.0}, {\"Location\": \"Brisbane\", \"WRP\": 2010.0, \"WH\": 193.0}, {\"Location\": \"Brisbane\", \"WRP\": 2010.0, \"WH\": 193.0}, {\"Location\": \"Brisbane\", \"WRP\": 1385.0, \"WH\": 193.0}, {\"Location\": \"Brisbane\", \"WRP\": 2156.0, \"WH\": 185.0}, {\"Location\": \"Brisbane\", \"WRP\": 2035.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 874.0, \"WH\": 190.0}, {\"Location\": \"Brisbane\", \"WRP\": 864.0, \"WH\": 170.0}, {\"Location\": \"Brisbane\", \"WRP\": 2035.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 3300.0, \"WH\": 185.0}, {\"Location\": \"Brisbane\", \"WRP\": 5450.0, \"WH\": 196.0}, {\"Location\": \"Brisbane\", \"WRP\": 4905.0, \"WH\": 178.0}, {\"Location\": \"Brisbane\", \"WRP\": 2035.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 5450.0, \"WH\": 196.0}, {\"Location\": \"Brisbane\", \"WRP\": 2035.0, \"WH\": 188.0}, {\"Location\": \"Brisbane\", \"WRP\": 2035.0, \"WH\": 188.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "x = 'WRP'\n",
    "y = 'WH'\n",
    "\n",
    "plot = alt.Chart(tennis_data_3).mark_point().encode(\n",
    "    x = alt.X(\"WRP\",\n",
    "              title = \"Winner Rank Points\",\n",
    "              scale=alt.Scale(zero=False)),\n",
    "    y = alt.Y(\"WH\", \n",
    "              title = \"Winner Heights\",\n",
    "              scale=alt.Scale(zero=False))\n",
    ").properties(\n",
    "    title = \"Winners' rank points and their corressponding Heights\"\n",
    ")\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3846716-82a1-468e-8c03-e3de086a6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the KNN regression model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "tennis_train, tennis_test = train_test_split(\n",
    "    tennis_data_3, train_size=0.75\n",
    ")\n",
    "\n",
    "# preprocess the data, make the pipeline\n",
    "tennis_preprocessor = make_column_transformer((StandardScaler(), [\"WRH\"]))\n",
    "tennis_pipeline = make_pipeline(tennis_preprocessor, KNeighborsRegressor())\n",
    "\n",
    "# create the 5-fold GridSearchCV object\n",
    "param_grid = {\n",
    "    \"kneighborsregressor__n_neighbors\": range(1, 201, 3),\n",
    "}\n",
    "tennis_gridsearch = GridSearchCV(\n",
    "    estimator=tennis_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98c82382-66a0-4f9e-87ea-b383482667d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 335 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n335 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3803, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'WRH'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/__init__.py\", line 448, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    raise KeyError(key) from err\nKeyError: 'WRH'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 723, in fit_transform\n    self._validate_column_callables(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 425, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/__init__.py\", line 456, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit the GridSearchCV object \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tennis_fit \u001b[38;5;241m=\u001b[39m \u001b[43mtennis_gridsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtennis_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWRP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtennis_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# retrieve the CV scores\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tennis_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tennis_fit\u001b[38;5;241m.\u001b[39mcv_results_)[\n\u001b[1;32m      8\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_kneighborsregressor__n_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 335 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n335 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3803, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'WRH'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/__init__.py\", line 448, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    raise KeyError(key) from err\nKeyError: 'WRH'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 723, in fit_transform\n    self._validate_column_callables(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 425, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/__init__.py\", line 456, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n"
     ]
    }
   ],
   "source": [
    "# fit the GridSearchCV object \n",
    "tennis_fit = tennis_gridsearch.fit(\n",
    "                  tennis_train[[\"WRP\"]],\n",
    "                  tennis_train[[\"WH\"]]\n",
    "              )\n",
    "# retrieve the CV scores\n",
    "tennis_results = pd.DataFrame(tennis_fit.cv_results_)[\n",
    "    [\"param_kneighborsregressor__n_neighbors\", \"mean_test_score\", \"std_test_score\"]\n",
    "]\n",
    "tennis_results = tennis_results.assign(    \n",
    "    sem_test_score = sacr_results[\"std_test_score\"] / 5**(1/2)\n",
    ").rename(\n",
    "    columns = {\"param_kneighborsregressor__n_neighbors\" : \"n_neighbors\"}\n",
    ").drop(\n",
    "    columns = [\"std_test_score\"]\n",
    ")\n",
    "tennis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed0ec4-00b2-469b-b3bc-9c7e33cc8f2a",
   "metadata": {},
   "source": [
    "Let's finally get to the interesting part of the project: Linear Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc2cef97-c53c-45c3-af9f-5e4c9a94f5f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [32, 11]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# fit the linear regression model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m lm \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m---> 16\u001b[0m \u001b[43mlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m   \u001b[49m\u001b[43mtennis_data_3_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWRP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m   \u001b[49m\u001b[43mtennis_data_3_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# make a dataframe containing slope and intercept coefficients\u001b[39;00m\n\u001b[1;32m     22\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslope\u001b[39m\u001b[38;5;124m\"\u001b[39m: lm\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m\"\u001b[39m: lm\u001b[38;5;241m.\u001b[39mintercept_})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_base.py:649\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    645\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    647\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 649\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    654\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    655\u001b[0m )\n\u001b[1;32m    657\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[1;32m    658\u001b[0m     X,\n\u001b[1;32m    659\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    663\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1105\u001b[0m     X,\n\u001b[1;32m   1106\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1118\u001b[0m )\n\u001b[1;32m   1120\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1122\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [32, 11]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "tennis_data_3_train, tennis_data_3_test = train_test_split(\n",
    "    tennis_data_3, train_size=0.75\n",
    ")\n",
    "\n",
    "# fit the linear regression model\n",
    "lm = LinearRegression()\n",
    "lm.fit(\n",
    "   tennis_data_3_train[[\"WRP\"]],\n",
    "   tennis_data_3_test[[\"WH\"]]\n",
    ")\n",
    "\n",
    "# make a dataframe containing slope and intercept coefficients\n",
    "pd.DataFrame({\"slope\": lm.coef_[0], \"intercept\": lm.intercept_})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
